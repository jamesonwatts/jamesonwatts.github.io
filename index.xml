<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jameson Watts, Ph.D. on Jameson Watts, Ph.D.</title>
    <link>/</link>
    <description>Recent content in Jameson Watts, Ph.D. on Jameson Watts, Ph.D.</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Mon, 15 Oct 2018 00:00:00 -0700</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>The Downside of Prominence in Network of Marketing Alliances</title>
      <link>/publication/downside-of-prominence/</link>
      <pubDate>Wed, 27 Nov 2019 00:00:00 -0800</pubDate>
      
      <guid>/publication/downside-of-prominence/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A New Database for Context-Sensitive Semantic Relatedness</title>
      <link>/post/a-new-database-for-context-sensitive-semantic-relatedness/</link>
      <pubDate>Mon, 18 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/a-new-database-for-context-sensitive-semantic-relatedness/</guid>
      <description>


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
use_python(&amp;quot;/Applications/anaconda/bin/python&amp;quot;, required = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;omg-python-in-rstudio&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;OMG Python in RStudio!&lt;/h1&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;for i in range(10):
  if(i&amp;lt;5):
    print(&amp;quot;Hello Little World  &amp;quot;+str(i))
  else:
    print(&amp;quot;Hello Big World  &amp;quot;+str(i))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Hello Little World  0
## Hello Little World  1
## Hello Little World  2
## Hello Little World  3
## Hello Little World  4
## Hello Big World  5
## Hello Big World  6
## Hello Big World  7
## Hello Big World  8
## Hello Big World  9&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;okay-moving-on.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Okay, moving on.&lt;/h2&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas as pd
import chardet
import numpy as np
homedir = &amp;quot;/Users/jwatts/Dropbox/Website&amp;quot;
with open(f&amp;quot;{homedir}/private/master.csv&amp;quot;, &amp;#39;rb&amp;#39;) as f:
    result = chardet.detect(f.read())  # or readline if the file is large
dfi = pd.read_csv(f&amp;quot;{homedir}/private/master.csv&amp;quot;, encoding=result[&amp;#39;encoding&amp;#39;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## sys:1: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#agreement stats
taskdata = {&amp;quot;ENTERTAINMENT&amp;quot;:{},&amp;quot;TECHNOLOGY&amp;quot;:{},&amp;quot;POLITICS&amp;quot;:{}}
for index, row in dfi.iterrows():
    for j in range(50):
        compare = row[&amp;quot;Input.Pairwise{:02}-P1&amp;quot;.format(j+1)]+&amp;quot;~&amp;quot;+row[&amp;quot;Input.Pairwise{:02}-P2&amp;quot;.format(j+1)]
        answer = row[&amp;quot;Answer.Pairwise{:02}&amp;quot;.format(j+1)]
        context = row[&amp;quot;Input.Context&amp;quot;]
        if compare in taskdata[context]:
            taskdata[context][compare].append(answer) 
        else:
            taskdata[context][compare]=[answer]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#accumulate scores
pairs = {}
totalerrors=0
for index, row in dfi.iterrows(): 
    for j in range(50):
        p1 = row[&amp;quot;Input.Pairwise{:02}-P1&amp;quot;.format(j+1)]
        p2 = row[&amp;quot;Input.Pairwise{:02}-P2&amp;quot;.format(j+1)]
        compare = p1+&amp;quot;~&amp;quot;+p2
        context = row[&amp;quot;Input.Context&amp;quot;]
        judgements = np.mean(taskdata[context][compare])  
        
        if p1 not in pairs.keys():
            pairs[p1] = {&amp;quot;ENTERTAINMENT&amp;quot;:[],&amp;quot;TECHNOLOGY&amp;quot;:[],&amp;quot;POLITICS&amp;quot;:[],&amp;quot;W_ENTERTAINMENT&amp;quot;:[],&amp;quot;W_TECHNOLOGY&amp;quot;:[],&amp;quot;W_POLITICS&amp;quot;:[],&amp;quot;A_ENTERTAINMENT&amp;quot;:[],&amp;quot;A_TECHNOLOGY&amp;quot;:[],&amp;quot;A_POLITICS&amp;quot;:[],&amp;quot;ALL&amp;quot;:[],&amp;quot;AGE&amp;quot;:[],&amp;quot;EDU&amp;quot;:[],&amp;quot;ETH&amp;quot;:[],&amp;quot;GEN&amp;quot;:[],&amp;quot;US&amp;quot;:[]}
        
        answer = row[&amp;quot;Answer.Pairwise{:02}&amp;quot;.format(j+1)]
        weight = (row[&amp;#39;Answer.Familiarity&amp;#39;]/2)-0.5 #1-&amp;gt;0, 2-&amp;gt;0.5, 3-&amp;gt;1
        pairs[p1][context].append(1-answer) #0 means focus pair is more related.
        pairs[p1][f&amp;quot;W_{context}&amp;quot;].append((1-answer)*weight) #0 means focus pair is more related.
        
        pairs[p1][f&amp;quot;A_{context}&amp;quot;].append(1 if judgements == 0 or judgements == 1 else 0) #agree if value is either 0 or 2
        pairs[p1][&amp;#39;ALL&amp;#39;].append(1-answer) #0 means focus pair is more related.
        pairs[p1][&amp;#39;AGE&amp;#39;].append(row[&amp;#39;Answer.Age&amp;#39;])
        pairs[p1][&amp;#39;EDU&amp;#39;].append(row[&amp;#39;Answer.Education&amp;#39;])
        pairs[p1][&amp;#39;ETH&amp;#39;].append(1 if row[&amp;#39;Answer.Ethnicity&amp;#39;]==&amp;#39;White&amp;#39; else 0)
        pairs[p1][&amp;#39;GEN&amp;#39;].append(1 if row[&amp;#39;Answer.Gender&amp;#39;]==&amp;#39;Male&amp;#39; else 0)
        pairs[p1][&amp;#39;US&amp;#39;].append(1 if row[&amp;#39;Answer.country&amp;#39;]==&amp;#39;US&amp;#39; else 0)
                        
dfi.to_csv(f&amp;quot;{homedir}/master-results.csv&amp;quot;)                
print(&amp;quot;finished aggregation&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## finished aggregation&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;with open(f&amp;quot;{homedir}/private/data_core.csv&amp;quot;, &amp;#39;rb&amp;#39;) as f:
    result = chardet.detect(f.read())  # or readline if the file is large
dfs = pd.read_csv(f&amp;quot;{homedir}/private/data_core.csv&amp;quot;, encoding=result[&amp;#39;encoding&amp;#39;])
for index, row in dfs.iterrows():
    mpair = f&amp;quot;{row[&amp;#39;Word1&amp;#39;].upper()} - {row[&amp;#39;Word2&amp;#39;].upper()}&amp;quot;
    if mpair in pairs:
        pairs[mpair][&amp;quot;MEN&amp;quot;] = row[&amp;#39;Relatedness&amp;#39;]/50.0
import numpy as np
dfo = pd.DataFrame({&amp;quot;PAIR&amp;quot;:[pair for pair in pairs],
#                    &amp;quot;RATINGS ENTERTAINMENT&amp;quot;:[len(pairs[pair][&amp;#39;ENTERTAINMENT&amp;#39;]) for pair in pairs],
                    &amp;quot;S-ENT&amp;quot;:[np.mean(pairs[pair][&amp;#39;ENTERTAINMENT&amp;#39;]) for pair in pairs],
                    &amp;quot;W-ENT&amp;quot;:[np.mean(pairs[pair][&amp;#39;W_ENTERTAINMENT&amp;#39;]) for pair in pairs],
                    &amp;quot;A-ENT&amp;quot;:[np.mean(pairs[pair][&amp;#39;A_ENTERTAINMENT&amp;#39;]) for pair in pairs],
#                    &amp;quot;RATINGS TECHNOLOGY&amp;quot;:[len(pairs[pair][&amp;#39;TECHNOLOGY&amp;#39;]) for pair in pairs],
                    &amp;quot;S-TEC&amp;quot;:[np.mean(pairs[pair][&amp;#39;TECHNOLOGY&amp;#39;]) for pair in pairs],
                    &amp;quot;W-TEC&amp;quot;:[np.mean(pairs[pair][&amp;#39;W_TECHNOLOGY&amp;#39;]) for pair in pairs],
                    &amp;quot;A-TEC&amp;quot;:[np.mean(pairs[pair][&amp;#39;A_TECHNOLOGY&amp;#39;]) for pair in pairs],
#                    &amp;quot;RATINGS POLITICS&amp;quot;:[len(pairs[pair][&amp;#39;POLITICS&amp;#39;]) for pair in pairs],
                    &amp;quot;S-POL&amp;quot;:[np.mean(pairs[pair][&amp;#39;POLITICS&amp;#39;]) for pair in pairs],
                    &amp;quot;W-POL&amp;quot;:[np.mean(pairs[pair][&amp;#39;W_POLITICS&amp;#39;]) for pair in pairs],
                    &amp;quot;A-POL&amp;quot;:[np.mean(pairs[pair][&amp;#39;A_POLITICS&amp;#39;]) for pair in pairs],
#                    &amp;quot;RATINGS ALL&amp;quot;:[len(pairs[pair][&amp;#39;ALL&amp;#39;]) for pair in pairs],
                    &amp;quot;S-ALL&amp;quot;:[np.mean(pairs[pair][&amp;#39;ALL&amp;#39;]) for pair in pairs],
                    &amp;quot;D-AGE&amp;quot;:[np.mean(pairs[pair][&amp;#39;AGE&amp;#39;]) for pair in pairs],
                    &amp;quot;D-EDU&amp;quot;:[np.mean(pairs[pair][&amp;#39;EDU&amp;#39;]) for pair in pairs],
                    &amp;quot;D-ETH&amp;quot;:[np.mean(pairs[pair][&amp;#39;ETH&amp;#39;]) for pair in pairs],
                    &amp;quot;D-GEN&amp;quot;:[np.mean(pairs[pair][&amp;#39;GEN&amp;#39;]) for pair in pairs],
                    &amp;quot;D-USA&amp;quot;:[np.mean(pairs[pair][&amp;#39;US&amp;#39;]) for pair in pairs],
#                    &amp;quot;B-SPA&amp;quot;:[pairs[pair][&amp;#39;COMMON&amp;#39;] for pair in pairs],
                    &amp;quot;B-MEN&amp;quot;:[pairs[pair][&amp;#39;MEN&amp;#39;] for pair in pairs]})
dfo.to_csv(f&amp;quot;{homedir}/private/master-analysis.csv&amp;quot;, index=False) 
#descriptives
dfc = dfo[[&amp;#39;S-ALL&amp;#39;,&amp;#39;B-MEN&amp;#39;,&amp;#39;S-ENT&amp;#39;, &amp;#39;W-ENT&amp;#39;, &amp;#39;S-TEC&amp;#39;, &amp;#39;W-TEC&amp;#39;,&amp;#39;S-POL&amp;#39;,&amp;#39;W-POL&amp;#39;]].copy()
dfd = dfo[[&amp;#39;A-ENT&amp;#39;,&amp;#39;A-TEC&amp;#39;,&amp;#39;A-POL&amp;#39;,&amp;#39;D-AGE&amp;#39;,&amp;#39;D-EDU&amp;#39;,&amp;#39;D-ETH&amp;#39;,&amp;#39;D-GEN&amp;#39;,&amp;#39;D-USA&amp;#39;]].copy()
print(dfc.describe())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              S-ALL        B-MEN  ...        S-POL        W-POL
## count  1000.000000  1000.000000  ...  1000.000000  1000.000000
## mean      0.500402     0.503280  ...     0.510208     0.359470
## std       0.111213     0.246257  ...     0.122394     0.092682
## min       0.189427     0.020000  ...     0.171053     0.105263
## 25%       0.422414     0.280000  ...     0.422941     0.292720
## 50%       0.500000     0.520000  ...     0.500000     0.359375
## 75%       0.573183     0.740000  ...     0.594301     0.425449
## max       0.806167     0.980000  ...     0.843750     0.636364
## 
## [8 rows x 8 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(dfd.describe())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##              A-ENT        A-TEC  ...        D-GEN        D-USA
## count  1000.000000  1000.000000  ...  1000.000000  1000.000000
## mean      0.567766     0.557154  ...     0.688954     0.988339
## std       0.086913     0.088467  ...     0.032172     0.007314
## min       0.324675     0.253731  ...     0.588832     0.954955
## 25%       0.512821     0.500000  ...     0.668321     0.983640
## 50%       0.569231     0.552239  ...     0.689655     0.989583
## 75%       0.625000     0.615385  ...     0.710866     0.994798
## max       0.852941     0.805556  ...     0.794872     1.000000
## 
## [8 rows x 8 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(dfc.corr())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           S-ALL     B-MEN     S-ENT  ...     W-TEC     S-POL     W-POL
## S-ALL  1.000000  0.702187  0.830371  ...  0.863528  0.842840  0.811441
## B-MEN  0.702187  1.000000  0.577344  ...  0.570896  0.612975  0.602818
## S-ENT  0.830371  0.577344  1.000000  ...  0.577128  0.501787  0.492089
## W-ENT  0.812821  0.555053  0.978136  ...  0.569107  0.489126  0.477457
## S-TEC  0.883864  0.606761  0.584392  ...  0.976091  0.685619  0.654673
## W-TEC  0.863528  0.570896  0.577128  ...  1.000000  0.663676  0.628470
## S-POL  0.842840  0.612975  0.501787  ...  0.663676  1.000000  0.958225
## W-POL  0.811441  0.602818  0.492089  ...  0.628470  0.958225  1.000000
## 
## [8 rows x 8 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;a-cool-graph&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;A cool graph&lt;/h2&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import matplotlib.pyplot as plt
#plt.style.use(&amp;#39;grayscale&amp;#39;)
colors=[&amp;quot;C0&amp;quot;,&amp;quot;C1&amp;quot;,&amp;quot;C2&amp;quot;]
for context in taskdata.keys():
#    color = colors.pop()
#    print(color)
#    
    # get x and y vectors
    x = dfo[f&amp;quot;S-{context[0:3]}&amp;quot;]
    y = dfo[f&amp;quot;A-{context[0:3]}&amp;quot;]
    
    
    # calculate polynomial
    z = np.polyfit(x, y, 3)
    f = np.poly1d(z)
    print(f)
    
    # calculate new x&amp;#39;s and y&amp;#39;s
    x_new = np.linspace(0, 1, 50)
    y_new = f(x_new)
    
    plt.ylabel(&amp;quot;AGREEMENT&amp;quot;)
    plt.xlabel(&amp;quot;SCORE&amp;quot;)
#    plt.legend()
    plt.plot(x,y,&amp;quot;x&amp;quot;, label=&amp;#39;&amp;#39;)
    plt.plot(x_new, y_new, label=context)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           3       2
## -0.03582 x + 1.8 x - 1.753 x + 0.9641
##            3         2
## -0.002704 x + 1.722 x - 1.705 x + 0.9509
##         3          2
## 0.4936 x + 0.8905 x - 1.27 x + 0.888&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plt.legend()
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-03-18-a-new-database-for-context-sensitive-semantic-relatedness_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Craven Speed Clusters</title>
      <link>/post/craven-speed-clusters/</link>
      <pubDate>Wed, 20 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/craven-speed-clusters/</guid>
      <description>


&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
use_python(&amp;quot;/Applications/anaconda/bin/python&amp;quot;, required = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(&amp;quot;Hello World&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Hello World&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import pandas as pd
dfi = pd.read_csv(&amp;#39;/Users/jwatts/Dropbox/website/private/ECommerce.csv&amp;#39;)
print(dfi.describe)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;bound method NDFrame.describe of          cid  orders  avg_order_size  ...  last_order  recency  longevity
## 0        142      85      602.441294  ...     8/20/18        2        336
## 1        158       5      130.362000  ...     6/21/18       62        105
## 2        297       2      206.105000  ...     8/21/18        1        286
## 3        352       4       98.860000  ...     5/10/18      104        205
## 4        417       2       37.500000  ...     4/23/18      121        179
## 5        418       2      101.285000  ...      6/4/18       79        237
## 6        586       1      244.850000  ...    11/22/17      273          0
## 7        588       1       93.000000  ...      6/5/18       78          0
## 8        750       1      109.000000  ...      4/6/18      138          0
## 9        855       1       32.460000  ...     11/2/17      293          0
## 10       876       4     1302.292500  ...      8/9/18       13        297
## 11       910       4      403.837500  ...     7/13/18       40        240
## 12      1095       1       20.000000  ...      2/9/18      194          0
## 13      1128       1       88.000000  ...     9/29/17      327          0
## 14      1174       1       25.000000  ...     6/22/18       61          0
## 15      1250       1       25.000000  ...    10/17/17      309          0
## 16      1278       1       68.080000  ...     11/3/17      292          0
## 17      1392       2       50.745000  ...    10/10/17      316         16
## 18      1441      23      881.298261  ...     8/14/18        8        336
## 19      1446       3       79.650000  ...     6/15/18       68        128
## 20      1515      15      100.870000  ...     8/20/18        2        312
## 21      1570       6       35.228333  ...     7/18/18       35        147
## 22      1728       1        0.000000  ...     1/24/18      210          0
## 23      1763       2       53.120000  ...     6/11/18       72        189
## 24      1770       1        0.000000  ...     9/25/17      331          0
## 25      1864      18      360.291667  ...      8/6/18       16        322
## 26      1986       1      103.000000  ...     7/22/18       31          0
## 27      2062       1       30.000000  ...    11/27/17      268          0
## 28      2116       2       55.000000  ...     2/14/18      189         18
## 29      2148       3       57.453333  ...     6/22/18       61        251
## ...      ...     ...             ...  ...         ...      ...        ...
## 15870  80826       1       25.000000  ...     8/20/18        2          0
## 15871  80828       1       25.000000  ...     8/21/18        1          0
## 15872  80829       1       25.000000  ...     8/21/18        1          0
## 15873  80831       1       25.000000  ...     8/21/18        1          0
## 15874  80832       1       33.280000  ...     8/21/18        1          0
## 15875  80833       1       93.000000  ...     8/21/18        1          0
## 15876  80834       1       93.000000  ...     8/21/18        1          0
## 15877  80835       1       25.000000  ...     8/21/18        1          0
## 15878  80837       1       25.000000  ...     8/21/18        1          0
## 15879  80838       1       93.000000  ...     8/21/18        1          0
## 15880  80839       1       84.600000  ...     8/21/18        1          0
## 15881  80840       1       67.000000  ...     8/21/18        1          0
## 15882  80841       1       33.280000  ...     8/21/18        1          0
## 15883  80843       1       25.000000  ...     8/21/18        1          0
## 15884  80844       1       25.000000  ...     8/21/18        1          0
## 15885  80845       1        0.000000  ...     8/21/18        1          0
## 15886  80846       1       25.000000  ...     8/21/18        1          0
## 15887  80847       1      103.670000  ...     8/21/18        1          0
## 15888  80848       1       93.000000  ...     8/21/18        1          0
## 15889  80849       1       43.280000  ...     8/21/18        1          0
## 15890  80850       1       37.970000  ...     8/21/18        1          0
## 15891  80851       1       25.000000  ...     8/21/18        1          0
## 15892  80852       1      186.000000  ...     8/21/18        1          0
## 15893  80853       1       93.000000  ...     8/21/18        1          0
## 15894  80854       1       25.000000  ...     8/21/18        1          0
## 15895  80855       1        0.000000  ...     8/21/18        1          0
## 15896  80856       1       93.000000  ...     8/21/18        1          0
## 15897  80857       1       25.000000  ...     8/21/18        1          0
## 15898  80858       1      119.000000  ...     8/21/18        1          0
## 15899  80859       1        0.000000  ...     8/21/18        1          0
## 
## [15900 rows x 17 columns]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# import statements
from sklearn.datasets import make_blobs
import numpy as np
import matplotlib.pyplot as plt
# create blobs
data = make_blobs(n_samples=200, n_features=2, centers=4, cluster_std=1.6, random_state=50)
# create np array for data points
points = data[0]
# create scatter plot
plt.scatter(data[0][:,0], data[0][:,1], c=data[1], cmap=&amp;#39;viridis&amp;#39;)
plt.xlim(-15,15)
plt.ylim(-15,15)
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-20-craven-speed-clusters_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Example Page</title>
      <link>/tutorial/example/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0700</pubDate>
      
      <guid>/tutorial/example/</guid>
      <description>

&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;

&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;Please check with your parents before using any of the information on this website for nefarious purposes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Redefining the Market: A Treatise on Exchange and Shared Understanding</title>
      <link>/publication/redefining-market/</link>
      <pubDate>Sun, 20 May 2018 00:00:00 -0700</pubDate>
      
      <guid>/publication/redefining-market/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Trend Spotting: Using Text Analysis to Model Market Dynamics</title>
      <link>/publication/trend-spotting/</link>
      <pubDate>Tue, 27 Feb 2018 00:00:00 -0800</pubDate>
      
      <guid>/publication/trend-spotting/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Connected Consumers</title>
      <link>/publication/connected-consumers/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 -0800</pubDate>
      
      <guid>/publication/connected-consumers/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/talk/example/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0800</pubDate>
      
      <guid>/talk/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Academic&amp;rsquo;s &lt;em&gt;Slides&lt;/em&gt; feature and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Further talk details can easily be added to this page using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>When online visibility deters social interaction: The case of digital gifts</title>
      <link>/publication/online-visibility/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 -0700</pubDate>
      
      <guid>/publication/online-visibility/</guid>
      <description></description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0700</pubDate>
      
      <guid>/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0700</pubDate>
      
      <guid>/project/internal-project/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;

&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;

&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;

&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;

&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Strangers you may know: social surveillance and intimacy online</title>
      <link>/publication/strangers-you-may-know/</link>
      <pubDate>Tue, 15 Mar 2016 00:00:00 -0700</pubDate>
      
      <guid>/publication/strangers-you-may-know/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Social Visibility and the Gifting of Digital Goods</title>
      <link>/publication/social-visibility/</link>
      <pubDate>Tue, 03 Nov 2015 00:00:00 -0800</pubDate>
      
      <guid>/publication/social-visibility/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Supple Networks: Preferential Attachment by diversity in nascent social graphs</title>
      <link>/publication/supple-networks/</link>
      <pubDate>Mon, 01 Dec 2014 00:00:00 -0800</pubDate>
      
      <guid>/publication/supple-networks/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
